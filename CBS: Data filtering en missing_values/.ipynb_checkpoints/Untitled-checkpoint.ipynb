{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63041077-c39a-4a17-a9a0-af3f0bfbc28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[134, 134, 134, 134, 135, 140, 148, 159, 194, 203]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def weighted_slope(start_value, end_value, start_index, end_index):\n",
    "\n",
    "    distance = end_index - start_index\n",
    "    weight_start = distance / (start_index - 0.5)  # Assign a higher weight to the starting point\n",
    "    weight_end = distance / (end_index - 0.5)    # Assign a higher weight to the ending point\n",
    "\n",
    "    # Calculate the slope with weighted contributions\n",
    "    slope = (end_value - start_value) / (end_index - start_index)\n",
    "    weighted_slope = slope * ((weight_start + weight_end) / 2)\n",
    "\n",
    "    #weighted_slope = (end_value - start_value) / (end_index - start_index)\n",
    "    \n",
    "    return round(weighted_slope)\n",
    "\n",
    "\n",
    "def consecutive_extrapolation(buurt_data, start_index, end_index):\n",
    "\n",
    "    # Make sure right data type, improve \n",
    "    buurt_values = buurt_data.astype('Int64')\n",
    "\n",
    "    smal_known_i = buurt_values.first_valid_index()\n",
    "    larg_known_i = buurt_values.last_valid_index()\n",
    "\n",
    "    \n",
    "    # Compute slope between first and last known point\n",
    "    w_slope = weighted_slope(buurt_values.iloc[smal_known_i], buurt_values.iloc[larg_known_i], smal_known_i, larg_known_i)\n",
    "\n",
    "    # When the consecutive missing values occur at the beginning, begin iterating at the end.\n",
    "    if start_index == 0:\n",
    "        loop_start = len(buurt_values) - 1\n",
    "        loop_end = start_index - 1\n",
    "        direction = -1\n",
    "    \n",
    "    # When the consecutive missing values occur at the end or in between, begin iterating at the start.\n",
    "    else:\n",
    "        loop_start = 0\n",
    "        loop_end = len(buurt_values)\n",
    "        direction = 1\n",
    "        \n",
    "\n",
    "    for i in range(loop_start, loop_end, direction):\n",
    "\n",
    "        valid_indices = buurt_values[buurt_values.notna()].index\n",
    "\n",
    "        if pd.isna(buurt_values.iloc[i]):  # Only extrapolate missing values\n",
    "            \n",
    "            prev_index = valid_indices[valid_indices < i]\n",
    "            next_index = valid_indices[valid_indices > i]\n",
    "\n",
    "            if not prev_index.empty and not next_index.empty: \n",
    "\n",
    "                prev_known_value = buurt_values.iloc[prev_index.max()] \n",
    "                next_known_value = buurt_values.iloc[next_index.min()]\n",
    "\n",
    "                slope = weighted_slope(prev_known_value, next_known_value, prev_index.max(), next_index.min())\n",
    "\n",
    "                if start_index == 0:\n",
    "                    buurt_values.iloc[i] = buurt_values.iloc[i + 1] - slope\n",
    "                    \n",
    "                else: \n",
    "                    buurt_values.iloc[i] = buurt_values.iloc[i - 1] + slope\n",
    "\n",
    "                # print(prev_known_value, next_known_value)\n",
    "                # print(buurt_values.iloc[i], slope)\n",
    "\n",
    "            \n",
    "            elif prev_index.empty and not next_index.empty: \n",
    "                next_known_value = buurt_values.iloc[next_index.min()]\n",
    "                \n",
    "\n",
    "                \n",
    "                second_known_index = next_index[1]                \n",
    "                second_known_value = buurt_values.iloc[second_known_index]\n",
    "\n",
    "                slope = weighted_slope(next_known_value, second_known_value, next_index.min(), second_known_index)\n",
    "                \n",
    "                buurt_values.iloc[i] = buurt_values.iloc[i+1] - slope\n",
    "\n",
    "\n",
    "\n",
    "            elif not prev_index.empty and next_index.empty: \n",
    "                prev_known_value = buurt_values.iloc[prev_index.max()]\n",
    "\n",
    "                \n",
    "                second_known_index = prev_index[len(prev_index)-2]\n",
    "                second_known_value = buurt_values.iloc[second_known_index]\n",
    "\n",
    "\n",
    "                slope = weighted_slope(second_known_value, prev_known_value, second_known_index, prev_index.max())\n",
    "\n",
    "                buurt_values.iloc[i] = buurt_values.iloc[i-1] + slope \n",
    "                \n",
    "\n",
    "    return buurt_values\n",
    "\n",
    "\n",
    "# # verspreide huizen veendam [203, 205, 205, 211, 254, 276, 278, 292, 327, 353]\n",
    "# data1 = pd.Series([203, pd.NA, 205, 211, pd.NA, pd.NA, pd.NA, 292, 327, 353])\n",
    "\n",
    "\n",
    "# Bornsche maten [282, 297, 291, 307, 340, 356, 382, 423, 496, 529]\n",
    "#data2 = pd.Series([pd.NA, 297, pd.NA, pd.NA, 340, 356, 382, pd.NA, pd.NA, pd.NA])\n",
    "\n",
    "data3 = pd.Series([pd.NA, pd.NA, pd.NA, pd.NA, 135, 140, 148, 159, 194, 203])\n",
    "\n",
    "\n",
    "\n",
    "# consecutive_extrapolation(data1, 4, 6)\n",
    "\n",
    "\n",
    "# result = consecutive_extrapolation(data2, 7, 9)\n",
    "\n",
    "result = consecutive_extrapolation(data3, 0, 4)\n",
    "\n",
    "print(list(result))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6571f82-f22d-4d7d-9927-932aa5ab5c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "141f6c0c-06ff-4b91-b5b0-680adbe2ab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "### Print linearity per colomen\n",
    "####\n",
    "from itertools import islice\n",
    "from scipy.stats import linregress\n",
    "\n",
    "\n",
    "def linearity(df):\n",
    "\n",
    "    columns = df.columns\n",
    "\n",
    "    for col in columns[5:]:\n",
    "        buurten = df.groupby('gwb_code')[col]\n",
    "\n",
    "        print(f'Processing column: {col}')\n",
    "\n",
    "        \n",
    "        num_rows = 52960\n",
    "        missing_count = df[col].isnull().sum()        \n",
    "        if missing_count > 0:\n",
    "            proc = round((missing_count/num_rows) * 100, 2)\n",
    "\n",
    "            if proc > 3:\n",
    "                #print(f'Processing column: {col}')\n",
    "                buurt_count = 0\n",
    "                r_ = 0\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        #for buurt in islice(buurten, 8000):\n",
    "        for buurt in buurten:\n",
    "            \n",
    "            # buurt is a tuple: (group_name, group_data)\n",
    "            buurt_code, buurt_data = buurt\n",
    "\n",
    "            if buurt_data.isnull().any():\n",
    "                \n",
    "                # identife x and y, for linregression\n",
    "                x = buurt_data.dropna().index\n",
    "                y = buurt_data.dropna()\n",
    "\n",
    "                if x.empty or y.empty:\n",
    "                    r_ =+ 0\n",
    "                    buurt_count =+ 1\n",
    "                    \n",
    "\n",
    "                else:   \n",
    "                    slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "                    r_sqrt = r_value**2 \n",
    "                        \n",
    "                    r_ =+ r_sqrt \n",
    "                    buurt_count =+ 1\n",
    "\n",
    "        \n",
    "        r_mean = r_ / buurt_count\n",
    "        print(f'For column: {col} --> r_value in missing columns: {r_mean}')\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059aa096-5e56-473f-ac6c-916339b95ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spline_interpolation(buurt_data, missing):\n",
    "\n",
    "    missing_index = buurt_data[buurt_data.isna()].index\n",
    "    print(missing_index)\n",
    "    buurt_values = buurt_data.astype('Int64')    \n",
    "    \n",
    "    buurt_values_P = buurt_values.interpolate(method='polynomial', order=2)\n",
    "    pred_P = buurt_values_P.iloc[missing_index]\n",
    "\n",
    "    buurt_values_S = buurt_values.interpolate(method='spline', order=2)\n",
    "    pred_S = buurt_values_S.iloc[missing_index]\n",
    "    #print(list(pred_S)[0])\n",
    "\n",
    "    # acc_P = (1 - np.abs(list(pred_P)[0] - missing) / missing) * 100\n",
    "    # acc_S = (1 - np.abs(list(pred_S)[0] - missing) / missing) * 100\n",
    "\n",
    "\n",
    "    mae_P = np.mean(np.abs(pred_P - missing))  # Mean Absolute Error for Polynomial\n",
    "    mae_S = np.mean(np.abs(pred_S - missing))  # Mean Absolute Error for Spline\n",
    "\n",
    "    # print(pred_P, missing)\n",
    "    \n",
    "    # print(mae_P)\n",
    "    # print(mae_S)\n",
    "    # print(f\"RealValue {missing} --- accuracy Poly {pred_P.tolist()} with {acc_P},    and Spline {pred_S.tolist()} with {acc_S}\")\n",
    "    \n",
    "    #return buurt_values_P#, buurt_values_S = buurt_values.interpolate(method='spline', order=2)\n",
    "\n",
    "\n",
    "\n",
    "#data1 = pd.Series([408, 547, 598, 560, 577, 632, pd.NA, 479, 355, 378])\n",
    "\n",
    "\n",
    "data2 = pd.Series([373, 355, 375, pd.NA, pd.NA, 295, 294, 329, 393, 404]) # missing = 389, 304\n",
    "data3 = pd.Series([217, 217, 227, pd.NA, 188, 202, 224, 268, 278]) # 176\n",
    "data4 = pd.Series([555, 524, 504, 519, pd.NA, 525, 525, 561, 644, 637]) # 506\n",
    "\n",
    "\n",
    "\n",
    "spline_interpolation(data2, [389, 304])\n",
    "# spline_interpolation(data3, 176)\n",
    "# spline_interpolation(data4, 506)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def spline_interpolation2(buurt_data):\n",
    "\n",
    "\n",
    "    buurt_values = buurt_data.astype('Int64')    \n",
    "    \n",
    "    buurt_values_P = buurt_values.interpolate(method='polynomial', order=2)\n",
    "\n",
    "    buurt_values_S = buurt_values.interpolate(method='spline', order=2)\n",
    "\n",
    "    return buurt_values_P, buurt_values_S\n",
    "\n",
    "data2 = pd.Series([373, 355, 375, pd.NA, pd.NA, 295, 294, 329, 393, 404]) # missing = 389, 304\n",
    "data3 = pd.Series([217, 217, 227, pd.NA, 188, 202, 224, 268, 278]) # 176\n",
    "data4 = pd.Series([555, 524, 504, 519, pd.NA, 525, 525, 561, 644, 637]) # 506\n",
    "\n",
    "\n",
    "data5 = pd.Series([pd.NA, 524, 504, 519, pd.NA, 525, 525, pd.NA, pd.NA, pd.NA]) # 506\n",
    "\n",
    "buurt_values_P, buurt_values_S = spline_interpolation2(data5)\n",
    "print(buurt_values_P)\n",
    "print(buurt_values_S)\n",
    "\n",
    "# spline_interpolation(data3, 176)\n",
    "# spline_interpolation(data4, 506)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5226c67-4059-4647-a1db-42fa2e47047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_slope(start_value, end_value, start_index, end_index):\n",
    "    # Adjust weights to favor nearer points\n",
    "    weight_start = 1 / (start_index + 1)  # Higher weight for closer points\n",
    "    weight_end = 1 / (end_index + 1)     # Higher weight for closer points\n",
    "\n",
    "    # Calculate weighted slope\n",
    "    slope = (end_value - start_value) / (end_index - start_index)\n",
    "    weighted_slope = slope * ((weight_start + weight_end) / 2)\n",
    "    \n",
    "    return weighted_slope\n",
    "\n",
    "def consecutive_extrapolation(buurt_data):\n",
    "    buurt_values = buurt_data.astype('Float64')  # Ensure float for calculations\n",
    "    \n",
    "    # Indices of known and missing values\n",
    "    known_indices = buurt_values[buurt_values.notna()].index\n",
    "    missing_indices = buurt_values[buurt_values.isna()].index\n",
    "\n",
    "    for i in missing_indices:\n",
    "        # Identify closest known indices before and after\n",
    "        prev_known_indexes = known_indices[known_indices < i]\n",
    "        next_known_indexes = known_indices[known_indices > i]\n",
    "\n",
    "        if not prev_known_indexes.empty and not next_known_indexes.empty:\n",
    "            # Interpolate between two known values\n",
    "            prev_known_index = prev_known_indexes.max()\n",
    "            prev_value = buurt_values.iloc[prev_known_index]\n",
    "            \n",
    "            next_known_index = next_known_indexes.min()\n",
    "            next_value = buurt_values.iloc[next_known_index]\n",
    "\n",
    "            print(prev_value, next_value)\n",
    "            slope = weighted_slope(prev_value, next_value, prev_known_index, next_known_index)\n",
    "            buurt_values.iloc[i] = prev_value + slope * (i - prev_known_index)\n",
    "\n",
    "        elif not prev_known_indexes.empty and next_known_indexes.empty:\n",
    "            # Extrapolate based on previous known value\n",
    "\n",
    "            prev_known_index = prev_known_indexes.max()\n",
    "            prev_value = buurt_values.iloc[prev_known_index]\n",
    "            \n",
    "            second_prev_index = known_indices[known_indices < prev_known_index] if any(known_indices < prev_known_index) else None\n",
    "            \n",
    "            if second_prev_index is not None:\n",
    "                second_prev_value = buurt_values.iloc[second_prev_index]\n",
    "                slope = weighted_slope(second_prev_value, prev_value, second_prev_index, prev_known_index)\n",
    "                buurt_values.iloc[i] = prev_value + slope * (i - prev_known_index)\n",
    "\n",
    "        elif prev_known_indexes.empty and not next_known_indexes.empty:\n",
    "            # Extrapolate based on next known value\n",
    "\n",
    "            next_known_index = next_known_indexes.min()\n",
    "            next_value = buurt_values.iloc[next_known_index]\n",
    "\n",
    "            if next_known_index < len(buurt_values):  # Ensure next_known_index is within bounds\n",
    "\n",
    "                second_next_index = known_indices[known_indices > next_known_index]if any(known_indices > next_known_index) else None\n",
    "                \n",
    "                if second_next_index is not None:\n",
    "                    second_next_value = buurt_values.iloc[second_next_index]\n",
    "                    slope = weighted_slope(next_value, second_next_value, next_known_index, second_next_index)\n",
    "                    buurt_values.iloc[i] = next_value - slope * (next_known_index - i)\n",
    "\n",
    "    return buurt_values\n",
    "\n",
    "# data1 = pd.Series([pd.NA, pd.NA, pd.NA, 308, pd.NA, 421, 479, pd.NA, pd.NA, 605]) # 479\n",
    "# data2 = pd.Series([pd.NA, pd.NA, pd.NA, 308, pd.NA, 421, 479, pd.NA, pd.NA, pd.NA]) # 479\n",
    "\n",
    "# consecutive_extrapolation(data1)\n",
    "\n",
    "\n",
    "data3 = pd.Series([87, 87, 88, 94, 103, <NA>, <NA>, 163, 177, 181]])\n",
    "\n",
    "\n",
    "consecutive_extrapolation(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7363039-ccbd-4e94-a995-3380161d3709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "def mice(buurt_data, win_size=3):\n",
    "    # Convert the input data to a DataFrame\n",
    "    train = pd.DataFrame(buurt_data, columns=['y'])\n",
    "    \n",
    "    # Create rolling windows\n",
    "    X = sliding_window_view(train['y'].values, win_size)\n",
    "    \n",
    "    # Add month info (assuming the index is a datetime index)\n",
    "    # Here we create a mock index for demonstration purposes\n",
    "    train.index = pd.date_range(start='2023-01-01', periods=len(train), freq='M')\n",
    "    month_info = train.index.month.values[:len(X)]\n",
    "    \n",
    "    # Add month info to the windows\n",
    "    X = np.concatenate((X, month_info.reshape(-1, 1)), axis=1)\n",
    "\n",
    "    # Impute missing values using IterativeImputer\n",
    "    imp = IterativeImputer(random_state=0)\n",
    "    X_imp = imp.fit_transform(X)\n",
    "\n",
    "    # Extract the imputed values\n",
    "    matrix = X_imp[:, :win_size]\n",
    "    \n",
    "    # Collect diagonals for mean and std calculation\n",
    "    diags = [matrix[::-1, :].diagonal(i) for i in range(-matrix.shape[0] + 1, matrix.shape[1])]\n",
    "\n",
    "    # Prepare the DataFrame to store results\n",
    "    train['y_mean'] = np.nan\n",
    "    train['y_std'] = np.nan\n",
    "\n",
    "    # Calculate mean and std for each diagonal\n",
    "    for i, v in enumerate(diags):\n",
    "        if len(v) > 0:  # Ensure there are values to calculate mean/std\n",
    "            train.iloc[i, 1] = np.mean(v)\n",
    "            train.iloc[i, 2] = np.std(v)\n",
    "\n",
    "    return train\n",
    "\n",
    "# Example usage\n",
    "data1 = pd.Series([pd.NA, pd.NA, pd.NA, 308, 393, 421, 479, pd.NA, 598, 605])  # Example data\n",
    "result = mice(data1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ac566f-542e-4782-bcc9-4d95a884387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def ridge_regression_impute(data, degree=2, alpha=1.0):\n",
    "    # Prepare the data\n",
    "    years = np.arange(len(data)).reshape(-1, 1)  # Create an array of indices (0, 1, 2, ...)\n",
    "    observations = data.values.astype(float)  # Convert to float for regression\n",
    "\n",
    "    # Create a mask for missing values\n",
    "    mask = ~np.isnan(observations)\n",
    "\n",
    "    # Fit a polynomial regression model only on non-missing values\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    X_poly = poly.fit_transform(years[mask])\n",
    "    model = Ridge(alpha=alpha)\n",
    "    model.fit(X_poly, observations[mask])\n",
    "\n",
    "    # Predict missing values\n",
    "    X_full_poly = poly.transform(years)\n",
    "    predictions = model.predict(X_full_poly)\n",
    "\n",
    "    # Create a new Series to hold the results\n",
    "    imputed_data = pd.Series(observations, index=data.index)\n",
    "    \n",
    "    # Fill in the missing values with predictions\n",
    "    imputed_data[~mask] = predictions[~mask]\n",
    "\n",
    "    return imputed_data\n",
    "\n",
    "# real values [299, 310, 315, 313, 217, 226, 233, 258, 316, 337]\n",
    "data1 = pd.Series([299, np.nan, 315, np.nan, 217, np.nan, np.nan, 258, 316, 337])  \n",
    "imputed_values = ridge_regression_impute(data1)\n",
    "\n",
    "print(imputed_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84515af2-f523-47de-a43b-620a22747a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # elif buurt_data.isnull().all() == 0:\n",
    "            #     #print(buurt_data)\n",
    "                \n",
    "            #     # identife x and y, for linregression\n",
    "            #     x = buurt_data.dropna().index\n",
    "            #     y = buurt_data.dropna()\n",
    "\n",
    "\n",
    "                  \n",
    "            #     slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "            #     r_sqrt = r_value**2 \n",
    "\n",
    "            #     if r_sqrt < 0.4:\n",
    "            #         print(f'{buurt_code}, met R-squared: {r_sqrt}')\n",
    "            #         print(list(buurt_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af574cb7-c3fd-4514-adce-f68efe7b3f97",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'NAType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 43\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buurt_values\n\u001b[1;32m     42\u001b[0m data1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries([pd\u001b[38;5;241m.\u001b[39mNA, \u001b[38;5;241m2200\u001b[39m, \u001b[38;5;241m2270\u001b[39m, \u001b[38;5;241m2270\u001b[39m, \u001b[38;5;241m2310\u001b[39m, \u001b[38;5;241m2510\u001b[39m, \u001b[38;5;241m2860\u001b[39m, \u001b[38;5;241m3010\u001b[39m, \u001b[38;5;241m3050\u001b[39m, pd\u001b[38;5;241m.\u001b[39mNA])\n\u001b[0;32m---> 43\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mlinear_interpolation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m, in \u001b[0;36mlinear_interpolation\u001b[0;34m(buurt_data)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlinear_interpolation\u001b[39m(buurt_data):\n\u001b[0;32m----> 5\u001b[0m     buurt_values \u001b[38;5;241m=\u001b[39m \u001b[43mbuurt_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Use float to handle NaN values\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m buurt_values\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;66;03m# Extrapolation: when there is a missing value at the beginning\u001b[39;00m\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misna(buurt_values\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotna(buurt_values\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6639\u001b[0m     ]\n\u001b[1;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'NAType'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def linear_interpolation(buurt_data):\n",
    "    buurt_values = buurt_data.astype(float)  # Use float to handle NaN values\n",
    "\n",
    "    while buurt_values.isnull().sum() > 0:\n",
    "        # Extrapolation: when there is a missing value at the beginning\n",
    "        if pd.isna(buurt_values.iloc[0]) and pd.notna(buurt_values.iloc[-1]):\n",
    "            if len(buurt_values) > 2 and pd.isna(buurt_values.iloc[2]):\n",
    "                buurt_values = buurt_values.interpolate(method='linear', limit_direction='forward')\n",
    "            if len(buurt_values) > 1:\n",
    "                slope = buurt_values.iloc[1] - buurt_values.iloc[0]\n",
    "                buurt_values.iloc[0] = buurt_values.iloc[1] - slope\n",
    "\n",
    "        # Extrapolation: when there is a missing value at the end\n",
    "        elif pd.isna(buurt_values.iloc[-1]) and pd.notna(buurt_values.iloc[0]):\n",
    "            if len(buurt_values) > 2 and pd.isna(buurt_values.iloc[-3]):\n",
    "                buurt_values = buurt_values.interpolate(method='linear', limit_direction='backward')\n",
    "            if len(buurt_values) > 1:\n",
    "                slope = buurt_values.iloc[-2] - buurt_values.iloc[-3]\n",
    "                buurt_values.iloc[-1] = buurt_values.iloc[-2] + slope\n",
    "\n",
    "        # Extrapolation: when there are missing values at both ends\n",
    "        elif pd.isna(buurt_values.iloc[0]) and pd.isna(buurt_values.iloc[-1]):\n",
    "            if len(buurt_values) > 2 and (pd.isna(buurt_values.iloc[2]) or pd.isna(buurt_values.iloc[-3])):\n",
    "                interpolated_subset = buurt_values.iloc[1:-1].interpolate(method='linear', limit_direction='forward')\n",
    "                buurt_values.iloc[1:-1] = interpolated_subset\n",
    "            if len(buurt_values) > 2:\n",
    "                slope1 = (buurt_values.iloc[2] - buurt_values.iloc[1])\n",
    "                buurt_values.iloc[0] = buurt_values.iloc[1] - slope1\n",
    "                slope2 = (buurt_values.iloc[-2] - buurt_values.iloc[-3])\n",
    "                buurt_values.iloc[-1] = buurt_values.iloc[-2] + slope2\n",
    "\n",
    "        # Otherwise, just interpolate\n",
    "        else:\n",
    "            buurt_values = buurt_values.interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "    return buurt_values\n",
    "\n",
    "\n",
    "data1 = pd.Series([pd.NA, 2200, 2270, 2270, 2310, 2510, 2860, 3010, 3050, pd.NA])\n",
    "result = linear_interpolation(data1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530105be-0d3b-4c2a-b310-932843722f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a185c8-e606-46ca-aef8-98ec4f2e2709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a3f3dd-0e9d-4085-9537-eee4a3dbbea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
