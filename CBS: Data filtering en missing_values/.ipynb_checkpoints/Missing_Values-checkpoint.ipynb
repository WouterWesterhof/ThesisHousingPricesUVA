{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbb98760-7d19-40d7-b796-b91c1bd46930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file = 'filtered_w_missing_cbs_incl14.csv'\n",
    "cbs_file_raw = pd.read_csv(file, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac52fb77-3aa4-4d07-a8f5-bc488ba4cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import linregress\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from itertools import islice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bad2ecd8-1fb3-4e9a-b3b9-a65d5de1bf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest streak: 3, Start index: 3, End index: 5\n"
     ]
    }
   ],
   "source": [
    "def count_consecutive_mv(buurt_values: list):\n",
    "    \"\"\"Counts what the highest consecutive values missing\"\"\"\n",
    "\n",
    "   \n",
    "    start_index, end_index = None, None\n",
    "    consecutive_count, highest_count = 0, 0\n",
    "    temp_start = None  # Temporary start index for the current streak\n",
    "    \n",
    "    \n",
    "    for i in range(len(buurt_values)):\n",
    "        if pd.isna(buurt_values[i]) and pd.isna(buurt_values[i - 1]):\n",
    "            consecutive_count += 1\n",
    "            \n",
    "            if consecutive_count > highest_count:\n",
    "                highest_count = consecutive_count\n",
    "        \n",
    "        elif pd.isna(\n",
    "            buurt_values[i]) and pd.notna(buurt_values[i - 1]):\n",
    "            consecutive_count = 1\n",
    "\n",
    "            temp_start = i\n",
    "            \n",
    "            if consecutive_count > highest_count:\n",
    "                highest_count = consecutive_count\n",
    "                start_index = temp_start\n",
    "\n",
    "        else:\n",
    "            \n",
    "            if pd.isna(buurt_values[i - 1]):\n",
    "                if consecutive_count == highest_count:\n",
    "                    end_index = (i - 1)\n",
    "                    start_index = temp_start\n",
    "\n",
    "            consecutive_count = 0\n",
    "                \n",
    "            \n",
    "    \n",
    "    return highest_count, start_index, end_index\n",
    "\n",
    "# Example usage\n",
    "data1 = pd.Series([pd.NA, pd.NA, pd.NA, 308, 393, 421, pd.NA, 479, 598, 605])\n",
    "data1 = pd.Series([pd.NA, pd.NA, 308, pd.NA, pd.NA, pd.NA, 421, pd.NA, 598, 605])\n",
    "\n",
    "result = count_consecutive_mv(data1.tolist())\n",
    "print(f\"Longest streak: {result[0]}, Start index: {result[1]}, End index: {result[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d62cc68-f5c1-4d1b-814c-021f23f5fad9",
   "metadata": {},
   "source": [
    "## 1. Techniques for handling missing values\n",
    "\n",
    "### 1.1 Inter- and extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93962014-c54d-4e65-8422-6cb5d0c9362a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2182.653061\n",
      "1         2200.0\n",
      "2         2235.0\n",
      "3         2270.0\n",
      "4         2390.0\n",
      "5         2510.0\n",
      "6         2860.0\n",
      "7         3010.0\n",
      "8         3050.0\n",
      "9    3067.346939\n",
      "dtype: Float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def slope(y1, y2, x1, x2):\n",
    "    return (y2 - y1) / (x2 - x1)\n",
    "\n",
    "def linear_interpolation(buurt_data):\n",
    "    \n",
    "    buurt_values = buurt_data.astype('Float64')\n",
    "    buurt_values = buurt_values.reset_index(drop=True)\n",
    "\n",
    "    smal_known_i = buurt_values.first_valid_index()\n",
    "    larg_known_i = buurt_values.last_valid_index()\n",
    "\n",
    "\n",
    "    # Calculate overall slope using first and last known values\n",
    "    line_slope = slope(\n",
    "        buurt_values.iloc[smal_known_i], \n",
    "        buurt_values.iloc[larg_known_i], \n",
    "        smal_known_i, \n",
    "        larg_known_i\n",
    "    )\n",
    "\n",
    "    #print(f\"Overall slope: {line_slope}\")\n",
    "\n",
    "    while buurt_values.isnull().sum() > 0:\n",
    "        # Extrapolation: missing value at the beginning\n",
    "        if pd.isna(buurt_values.iloc[0]) and pd.notna(buurt_values.iloc[-1]):\n",
    "            # Distance from first known point\n",
    "            dist = smal_known_i - 0\n",
    "            total_dist = larg_known_i - smal_known_i\n",
    "            weight = dist / total_dist  # Weight factor based on distance\n",
    "            adjusted_slope = weight * line_slope  # Scale slope\n",
    "            buurt_values.iloc[0] = buurt_values.iloc[1] - adjusted_slope\n",
    "\n",
    "        # Extrapolation: missing value at the end\n",
    "        elif pd.isna(buurt_values.iloc[-1]) and pd.notna(buurt_values.iloc[0]):\n",
    "            # Distance from last known point\n",
    "            dist = len(buurt_values) - 1 - larg_known_i\n",
    "            total_dist = larg_known_i - smal_known_i\n",
    "            weight = dist / total_dist  # Weight factor based on distance\n",
    "            adjusted_slope = weight * line_slope  # Scale slope\n",
    "            buurt_values.iloc[-1] = buurt_values.iloc[-2] + adjusted_slope\n",
    "\n",
    "        # Extrapolation: missing values at both ends\n",
    "        elif pd.isna(buurt_values.iloc[0]) and pd.isna(buurt_values.iloc[-1]):\n",
    "            # Apply weighted slope at both ends\n",
    "            dist1 = smal_known_i - 0\n",
    "            dist2 = len(buurt_values) - 1 - larg_known_i\n",
    "            total_dist = larg_known_i - smal_known_i\n",
    "            weight1 = dist1 / total_dist\n",
    "            weight2 = dist2 / total_dist\n",
    "            adjusted_slope1 = weight1 * line_slope\n",
    "            adjusted_slope2 = weight2 * line_slope\n",
    "            buurt_values.iloc[0] = buurt_values.iloc[1] - adjusted_slope1\n",
    "            buurt_values.iloc[-1] = buurt_values.iloc[-2] + adjusted_slope2\n",
    "\n",
    "        # Otherwise, perform linear interpolation\n",
    "        else:\n",
    "            buurt_values = buurt_values.interpolate(method=\"linear\", limit_direction=\"both\")\n",
    "\n",
    "    return buurt_values\n",
    "\n",
    "# Example data\n",
    "data1 = pd.Series([pd.NA, 2200, pd.NA, 2270, pd.NA, 2510, 2860, 3010, 3050, pd.NA])\n",
    "\n",
    "# Apply function with weighted extrapolation\n",
    "result = linear_interpolation(data1)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d9a28b4-f8e3-4451-bbf4-bd2b97089d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2150.0\n",
      "1    2190.0\n",
      "2    2230.0\n",
      "3    2270.0\n",
      "4    2310.0\n",
      "5    2510.0\n",
      "6    2860.0\n",
      "7    3010.0\n",
      "8    3050.0\n",
      "9    3090.0\n",
      "dtype: Float64\n"
     ]
    }
   ],
   "source": [
    "def slope(y1, y2, x1, x2):\n",
    "    return (y2 - y1) / (x2 - x1)\n",
    "\n",
    "\n",
    "\n",
    "def consecutive_extrapolation(buurt_data, start_index, end_index):\n",
    "\n",
    "    buurt_values = pd.Series(list(buurt_data))\n",
    "    # Make sure right data type, improve \n",
    "    buurt_values = buurt_values.astype('Float64')\n",
    "\n",
    "    smal_known_i = buurt_values.first_valid_index()\n",
    "    larg_known_i = buurt_values.last_valid_index()\n",
    "    \n",
    "    #Compute slope between first and last known point\n",
    "    line_slope = slope(buurt_values.iloc[smal_known_i], buurt_values.iloc[larg_known_i], smal_known_i, larg_known_i)\n",
    "    \n",
    "    # When the consecutive missing values occur at the beginning, begin iterating at the end.\n",
    "    if start_index == 0:\n",
    "        loop_start = len(buurt_values) - 1\n",
    "        loop_end = start_index - 1\n",
    "        direction = -1\n",
    "    \n",
    "    # When the consecutive missing values occur at the end or in between, begin iterating at the start.\n",
    "    elif start_index != 0:\n",
    "        loop_start = 0\n",
    "        loop_end = len(buurt_values)\n",
    "        direction = 1\n",
    "        \n",
    "\n",
    "    for i in range(loop_start, loop_end, direction):\n",
    "\n",
    "        valid_indices = buurt_values[buurt_values.notna()].index\n",
    "\n",
    "        if pd.isna(buurt_values.iloc[i]):  # Only extrapolate missing values\n",
    "            \n",
    "            prev_index = valid_indices[valid_indices < i]\n",
    "            next_index = valid_indices[valid_indices > i]\n",
    "\n",
    "            if not prev_index.empty and not next_index.empty: \n",
    "                \n",
    "                prev_known_index = prev_index.max()\n",
    "                prev_known_value = buurt_values.iloc[prev_known_index] \n",
    "                next_known_index = next_index.min()\n",
    "                next_known_value = buurt_values.iloc[next_known_index]\n",
    "\n",
    "                line_slope = slope(prev_known_value, next_known_value, prev_known_index, next_known_index)\n",
    "                #print(slope)\n",
    "\n",
    "                if start_index == 0:\n",
    "                    buurt_values.iloc[i] = buurt_values.iloc[i + 1] - line_slope\n",
    "                    #buurt_values.iloc[i] = next_known_value + slope * (i - next_known_index)\n",
    "\n",
    "                else: \n",
    "                    buurt_values.iloc[i] = buurt_values.iloc[i - 1] + line_slope\n",
    "                    #buurt_values.iloc[i] = prev_known_value + slope * (i - prev_known_index)\n",
    "\n",
    "            \n",
    "            elif prev_index.empty and not next_index.empty: \n",
    "                next_known_index = next_index.min()\n",
    "                next_known_value = buurt_values.iloc[next_known_index]\n",
    "                \n",
    "                second_known_index = next_index[1]                \n",
    "                second_known_value = buurt_values.iloc[second_known_index]\n",
    "\n",
    "                line_slope = slope(next_known_value, second_known_value, next_known_index, second_known_index)\n",
    "                \n",
    "                buurt_values.iloc[i] = buurt_values.iloc[i+1] - line_slope\n",
    "\n",
    "\n",
    "            elif not prev_index.empty and next_index.empty: \n",
    "                prev_known_value = buurt_values.iloc[prev_index.max()]\n",
    "                \n",
    "                second_known_index = prev_index[len(prev_index)-2]\n",
    "                second_known_value = buurt_values.iloc[second_known_index]\n",
    "\n",
    "                line_slope = slope(second_known_value, prev_known_value, second_known_index, prev_index.max())\n",
    "\n",
    "                buurt_values.iloc[i] = buurt_values.iloc[i-1] + line_slope \n",
    "                \n",
    "\n",
    "    return buurt_values\n",
    "\n",
    "\n",
    "data1 = pd.Series([pd.NA, pd.NA, pd.NA, 2270, 2310, 2510, 2860, 3010, 3050, pd.NA])\n",
    "result = consecutive_extrapolation(data1, 0, 2)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2bf9ee-044f-4113-b386-a950df41a7bd",
   "metadata": {},
   "source": [
    "### 1.2 Spline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2adca8c8-2e27-4616-a5e8-9c4d68591ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "def spline_interpolation(buurt_data):\n",
    "\n",
    "    buurt_values = buurt_data.astype('Float64')\n",
    "    \n",
    "    x = np.arange(len(buurt_values))\n",
    "    \n",
    "    # Create a mask for the valid (non-NaN) values\n",
    "    mask = ~buurt_values.isna()\n",
    "    \n",
    "    # Fit cubic spline to the valid data points\n",
    "    cs = CubicSpline(x[mask], buurt_values[mask], bc_type='natural', extrapolate=False)\n",
    "    \n",
    "    # Generate new x values for interpolation\n",
    "    x_new = np.linspace(x.min(), x.max(), 100)\n",
    "    y_new = cs(x_new)\n",
    "    \n",
    "    # Interpolate the missing values in the original data\n",
    "    buurt_values[buurt_values.isna()] = cs(x[buurt_values.isna()])\n",
    "    \n",
    "    return buurt_values\n",
    "\n",
    "# # Real values [299, 310, 315, 313, 217, 226, 233, 258, 316, 337]\n",
    "# data1 = pd.Series([np.nan, np.nan, 315, np.nan, 217, np.nan, np.nan, 258, 316, 337])  \n",
    "# imputed_values = spline_interpolation(data1)\n",
    "\n",
    "# print(imputed_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "876c64c8-bb7f-4e68-807b-04a3e714b791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def variance_buurt(buurt_data, variance, non_missing_values):\n",
    "    \"\"\"\n",
    "    Calculates variance for a neighborhood and imputes missing values:\n",
    "    - If variance < 0.01, imputes with the mean.\n",
    "    - Otherwise, uses forward fill (last seen value).\n",
    "\n",
    "\n",
    "    Returns the imputed neighborhood data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Decide imputation strategy, low immpute mean\n",
    "    if variance < 0.01:\n",
    "        return buurt_data.fillna(non_missing_values.mean())  # Impute with mean\n",
    "        \n",
    "    else:\n",
    "        return buurt_data.ffill()  # Fix: Use .ffill() directly\n",
    "\n",
    "\n",
    "# data23 = pd.Series([np.nan, np.nan, 1, np.nan, 1, np.nan, np.nan, 1, 1, 1])  \n",
    "# variance = np.var(data23.dropna(), ddof=1)  # Sample variance\n",
    "# print(variance)\n",
    "\n",
    "# variance_buurt(data23, variance, data23.dropna())\n",
    "# # imputed_values = spline_interpolation(data1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2604a4a-a17d-44d9-9bb9-4481705f25a6",
   "metadata": {},
   "source": [
    "## Structure Handling MV's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "777bd90c-2ecd-4396-ba04-f861594ab15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing column: woz\n",
      "Processing column: a_inw\n",
      "Processing column: a_man\n",
      "Processing column: a_vrouw\n",
      "Processing column: a_geb\n",
      "Processing column: p_geb\n",
      "Processing column: a_ste\n",
      "Processing column: p_ste\n",
      "Processing column: a_hh\n",
      "Processing column: g_hhgro\n",
      "Processing column: bev_dich\n",
      "Processing column: a_woning\n",
      "Processing column: p_1gezw\n",
      "Processing column: p_mgezw\n",
      "Processing column: p_leegsw\n",
      "Processing column: p_koopw\n",
      "Processing column: p_huurw\n",
      "Processing column: p_wcorpw\n",
      "Processing column: p_ov_hw\n",
      "Processing column: g_ele\n",
      "Processing column: g_ele_vw\n",
      "Processing column: g_ele_hu\n",
      "Processing column: g_ele_ko\n",
      "Processing column: g_gas\n",
      "Processing column: g_gas_vw\n",
      "Processing column: g_gas_hu\n",
      "Processing column: g_gas_ko\n",
      "Processing column: a_inkont\n",
      "Processing column: g_ink_po\n",
      "Processing column: g_ink_pi\n",
      "Processing column: p_ink_li\n",
      "Processing column: p_ink_hi\n",
      "Processing column: p_hh_li\n",
      "Processing column: p_hh_hi\n",
      "Processing column: p_hh_lkk\n",
      "Processing column: p_hh_osm\n",
      "Processing column: a_soz_wb\n",
      "Processing column: a_soz_ao\n",
      "Processing column: a_soz_ww\n",
      "Processing column: a_soz_ow\n",
      "Processing column: a_bedv\n",
      "Processing column: a_bed_a\n",
      "Processing column: a_bed_bf\n",
      "Processing column: a_bed_gi\n",
      "Processing column: a_bed_hj\n",
      "Processing column: a_bed_kl\n",
      "Processing column: a_bed_mn\n",
      "Processing column: a_bed_ru\n",
      "Processing column: a_pau\n",
      "Processing column: a_bst_b\n",
      "Processing column: a_bst_nb\n",
      "Processing column: g_pau_hh\n",
      "Processing column: g_pau_km\n",
      "Processing column: a_m2w\n",
      "Processing column: g_afs_hp\n",
      "Processing column: g_afs_gs\n",
      "Processing column: g_afs_kv\n",
      "Processing column: g_afs_sc\n",
      "Processing column: g_3km_sc\n",
      "Processing column: a_opp_ha\n",
      "Processing column: a_lan_ha\n",
      "Processing column: a_wat_ha\n",
      "Processing column: pst_mvp\n",
      "Processing column: pst_dekp\n",
      "Processing column: ste_mvs\n",
      "Processing column: ste_oad\n"
     ]
    }
   ],
   "source": [
    "### import matplotlib.pyplot as plt\n",
    "from itertools import islice\n",
    "from scipy.stats import linregress\n",
    "\n",
    "\n",
    "def main_strcuture_handling_mv(df):\n",
    "    \"\"\"Fills missing values based on linear regression and interpolation techniques.\"\"\"\n",
    "    # Create a new DataFrame to store the results and copy the first 5 rows entirely from the original DataFrame\n",
    "    new_df = cbs_file_raw[['regio', 'gm_naam', 'gwb_code', 'ind_wbi', 'year']].copy()   \n",
    "\n",
    "    # Select the colomns\n",
    "    columns = df.columns\n",
    "\n",
    "    \n",
    "    for col in columns[5:]:\n",
    "        print(f'Processing column: {col}')\n",
    "        \n",
    "        missing_count = df[col].isnull().sum()\n",
    "        if missing_count == 0:\n",
    "            new_df[col] = df[col]\n",
    "            continue\n",
    "\n",
    "        # Groepeer buurten om er door te itereren en per colom de ontbrekende waarde te vinden\n",
    "        buurten = df.groupby('gwb_code')[col]\n",
    "        \n",
    "        for buurt_code, buurt_data in buurten:\n",
    "            row_index = buurt_data.index\n",
    "\n",
    "            if buurt_data.isnull().any():\n",
    "                x = buurt_data.dropna().index\n",
    "                y = buurt_data.dropna()\n",
    "\n",
    "                if (x.empty or y.empty) or (len(buurt_data[buurt_data.isnull()]) >= 7): \n",
    "                    new_df.loc[row_index, col] = buurt_data  # Leave it for MICE later\n",
    "                \n",
    "                else: #tef\n",
    "                    # First check on variance, if low impute data with mean, of fill\n",
    "                    variance = np.var(buurt_data.dropna(), ddof=1)  # Sample variance\n",
    "                    if variance <= 1:\n",
    "                        handled_data = variance_buurt(buurt_data, variance, buurt_data.dropna())\n",
    "\n",
    "                    else: #tef\n",
    "                        slope, intercept, r_value, _, _ = linregress(x, y)\n",
    "                        r_sqrt = r_value**2 \n",
    "    \n",
    "                        # Wanneer er 1 missing value is in de buurt\n",
    "                        if len(buurt_data[buurt_data.isnull()]) == 1: \n",
    "                            if r_sqrt >= 0.7:\n",
    "                                #print(buurt_data)\n",
    "                                handled_data = linear_interpolation(buurt_data) \n",
    "                                \n",
    "                            # Als r-waarde kleiner of gelijk is aan 75%: Gebruik .... voor ontbrekende waarden\n",
    "                            elif r_sqrt < 0.7:\n",
    "                                handled_data = spline_interpolation(buurt_data)                          \n",
    "                                #print(buurt_data)\n",
    "                                #for original, handled in zip(buurt_data, handled_data):\n",
    "                                #print(f\"Case2: {str(original):<15} {str(handled):<15}\")\n",
    "           \n",
    "                        \n",
    "                        # There are multiple missing_values\n",
    "                        else:\n",
    "                            consecutive_coount, start_index, end_index = count_consecutive_mv(list(buurt_data))\n",
    "        \n",
    "                            # When there arent any consecutive missing values\n",
    "                            if consecutive_coount == 1:\n",
    "                                \n",
    "                                if r_sqrt >= 0.7:\n",
    "                                    handled_data = linear_interpolation(buurt_data)\n",
    "    \n",
    "                                elif r_sqrt < 0.7:\n",
    "                                    handled_data = spline_interpolation(buurt_data)\n",
    "                                    \n",
    "                            elif consecutive_coount > 1:\n",
    "                                if r_sqrt >= 0.7:\n",
    "                                    handled_data = consecutive_extrapolation(buurt_data, start_index, end_index)\n",
    "                                    \n",
    "                                elif r_sqrt < 0.7:\n",
    "                                    handled_data = spline_interpolation(buurt_data)  \n",
    "                                    \n",
    "                    \n",
    "                # Make sure handled data has same dtype and index as buurt_data\n",
    "                handled_data = handled_data.astype(buurt_data.dtype)\n",
    "                handled_data.index = buurt_data.index \n",
    "                \n",
    "                # Update the new DataFrame with handled data\n",
    "                new_df.loc[row_index, col] = handled_data\n",
    "\n",
    "            else: \n",
    "                # If no missing values, copy the original data\n",
    "                new_df.loc[row_index, col] = buurt_data\n",
    "\n",
    "\n",
    "    return new_df\n",
    "                    \n",
    "\n",
    "\n",
    "new_df = main_strcuture_handling_mv(cbs_file_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a257753e-4dc5-4412-8479-a2a5127a2fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_mice_df = new_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46d30db8-5d3e-43d2-a6f3-cf8d11e1fb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Completing matrix with shape (51854, 69)\n",
      "[IterativeImputer] Ending imputation round 1/50, elapsed time 26.20\n",
      "[IterativeImputer] Change: 62.510786464896356, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 2/50, elapsed time 51.70\n",
      "[IterativeImputer] Change: 19.884420168915454, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 3/50, elapsed time 77.65\n",
      "[IterativeImputer] Change: 6.954257156254338, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 4/50, elapsed time 103.36\n",
      "[IterativeImputer] Change: 4.054598052139049, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 5/50, elapsed time 128.87\n",
      "[IterativeImputer] Change: 2.979146507195815, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 6/50, elapsed time 153.78\n",
      "[IterativeImputer] Change: 2.471853814166466, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 7/50, elapsed time 178.60\n",
      "[IterativeImputer] Change: 2.111120775407422, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 8/50, elapsed time 203.45\n",
      "[IterativeImputer] Change: 1.821629885767061, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 9/50, elapsed time 227.08\n",
      "[IterativeImputer] Change: 1.573845992244135, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 10/50, elapsed time 250.78\n",
      "[IterativeImputer] Change: 1.3611730397264203, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 11/50, elapsed time 274.88\n",
      "[IterativeImputer] Change: 1.1783053804106647, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 12/50, elapsed time 298.24\n",
      "[IterativeImputer] Change: 1.0208475503293526, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 13/50, elapsed time 321.78\n",
      "[IterativeImputer] Change: 0.9032526573801523, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 14/50, elapsed time 344.63\n",
      "[IterativeImputer] Change: 0.8022040019271799, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 15/50, elapsed time 367.88\n",
      "[IterativeImputer] Change: 0.7140190089940769, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 16/50, elapsed time 391.12\n",
      "[IterativeImputer] Change: 0.6368654120603061, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 17/50, elapsed time 414.69\n",
      "[IterativeImputer] Change: 0.5692036697016892, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 18/50, elapsed time 438.94\n",
      "[IterativeImputer] Change: 0.5099513931991628, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 19/50, elapsed time 462.03\n",
      "[IterativeImputer] Change: 0.45822377786475554, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 20/50, elapsed time 485.43\n",
      "[IterativeImputer] Change: 0.4126670534501112, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 21/50, elapsed time 508.45\n",
      "[IterativeImputer] Change: 0.37228591920734194, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 22/50, elapsed time 532.04\n",
      "[IterativeImputer] Change: 0.3364192379389339, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 23/50, elapsed time 556.15\n",
      "[IterativeImputer] Change: 0.3044984373312035, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 24/50, elapsed time 579.33\n",
      "[IterativeImputer] Change: 0.27603352563476447, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 25/50, elapsed time 602.80\n",
      "[IterativeImputer] Change: 0.25060140140342696, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 26/50, elapsed time 626.32\n",
      "[IterativeImputer] Change: 0.2278360341035038, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 27/50, elapsed time 649.42\n",
      "[IterativeImputer] Change: 0.207420185418276, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 28/50, elapsed time 672.85\n",
      "[IterativeImputer] Change: 0.18907840866497191, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 29/50, elapsed time 696.97\n",
      "[IterativeImputer] Change: 0.17257111445685197, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 30/50, elapsed time 720.57\n",
      "[IterativeImputer] Change: 0.1579936751708239, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 31/50, elapsed time 743.93\n",
      "[IterativeImputer] Change: 0.1452727213185725, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 32/50, elapsed time 767.82\n",
      "[IterativeImputer] Change: 0.13368289145724935, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 33/50, elapsed time 791.52\n",
      "[IterativeImputer] Change: 0.12310958241705294, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 34/50, elapsed time 815.49\n",
      "[IterativeImputer] Change: 0.11345152013758461, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 35/50, elapsed time 839.31\n",
      "[IterativeImputer] Change: 0.10461901542084745, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 36/50, elapsed time 862.72\n",
      "[IterativeImputer] Change: 0.09653246875599197, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 37/50, elapsed time 886.47\n",
      "[IterativeImputer] Change: 0.08993208938357797, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 38/50, elapsed time 910.51\n",
      "[IterativeImputer] Change: 0.08931075954144446, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 39/50, elapsed time 934.19\n",
      "[IterativeImputer] Change: 0.08871976267194195, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 40/50, elapsed time 957.63\n",
      "[IterativeImputer] Change: 0.08816201242709865, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 41/50, elapsed time 981.56\n",
      "[IterativeImputer] Change: 0.08770154501611682, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 42/50, elapsed time 1005.44\n",
      "[IterativeImputer] Change: 0.08725842174852078, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 43/50, elapsed time 1029.69\n",
      "[IterativeImputer] Change: 0.08683162799629776, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 44/50, elapsed time 1053.39\n",
      "[IterativeImputer] Change: 0.08642010151206192, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 45/50, elapsed time 1077.24\n",
      "[IterativeImputer] Change: 0.08602277443521933, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 46/50, elapsed time 1101.13\n",
      "[IterativeImputer] Change: 0.08563860086421735, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 47/50, elapsed time 1126.78\n",
      "[IterativeImputer] Change: 0.0852665756547343, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 48/50, elapsed time 1150.20\n",
      "[IterativeImputer] Change: 0.08490574566451156, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 49/50, elapsed time 1173.83\n",
      "[IterativeImputer] Change: 0.08455521617299858, scaled tolerance: 0.012165092489749533 \n",
      "[IterativeImputer] Ending imputation round 50/50, elapsed time 1197.54\n",
      "[IterativeImputer] Change: 0.08421415365885491, scaled tolerance: 0.012165092489749533 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wouter/.local/lib/python3.10/site-packages/sklearn/impute/_iterative.py:825: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def convert_to_num(df):\n",
    "    labelencoder = LabelEncoder() \n",
    "    \n",
    "    # Fit and transform both 'gm_naam' and 'regio'\n",
    "    df['gm_naam'] = labelencoder.fit_transform(df['gm_naam'])\n",
    "    df['regio'] = labelencoder.fit_transform(df['regio'])\n",
    "\n",
    "    return df  # Return the entire dataframe with transformed categorical columns\n",
    "\n",
    "def df_for_training(df):\n",
    "    # Drop unwanted columns\n",
    "    df = df.drop(columns=['gwb_code', 'ind_wbi'], errors='ignore')\n",
    "\n",
    "    # Convert non-numeric columns to numeric\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype != 'float64' and df[col].dtype != 'int64':\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')  # Convert any other non-numeric columns\n",
    "\n",
    "    return df\n",
    "\n",
    "def mice(df):\n",
    "    converted_df = df.copy()\n",
    "    \n",
    "    # Replace gemeentenamen ('gm_naam') and 'regio' with integers\n",
    "    converted_df = convert_to_num(converted_df)\n",
    "    \n",
    "    # Prepare the DataFrame for training by handling numeric conversions\n",
    "    df_train = df_for_training(converted_df)\n",
    "    \n",
    "    numeric_columns = df_train.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_train = scaler.fit_transform(df_train)\n",
    "\n",
    "    # Impute the missing values\n",
    "    imputer = IterativeImputer(random_state=100, max_iter=50, tol=1e-4, verbose=2)\n",
    "    imputed_scaled = imputer.fit_transform(scaled_train)\n",
    "\n",
    "    # Reverse scaling and update the DataFrame\n",
    "    df_imputed = pd.DataFrame(scaler.inverse_transform(imputed_scaled), columns=numeric_columns)\n",
    "    converted_df[numeric_columns] = df_imputed\n",
    "\n",
    "    return df_imputed\n",
    "                                    \n",
    "non_mis_df = mice(before_mice_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b506822-6a5d-4f1a-b38c-c0cc23ed8d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        regio  gm_naam    year    woz   a_inw   a_man  a_vrouw      a_geb  \\\n",
      "0       264.0      0.0  2014.0  300.0  7885.0  3900.0   3980.0  65.000000   \n",
      "1       264.0      0.0  2015.0  294.0  7955.0  3935.0   4020.0  60.000000   \n",
      "2       264.0      0.0  2016.0  298.0  8055.0  3980.0   4075.0  65.000000   \n",
      "3       264.0      0.0  2017.0  312.0  8145.0  4025.0   4120.0  60.000000   \n",
      "4       264.0      0.0  2018.0  339.0  8210.0  4030.0   4175.0  65.000000   \n",
      "...       ...      ...     ...    ...     ...     ...      ...        ...   \n",
      "51849  1551.0    202.0  2020.0  466.0   515.0   260.0    260.0   0.000000   \n",
      "51850  1551.0    202.0  2021.0  478.0   510.0   255.0    255.0   5.000000   \n",
      "51851  1551.0    202.0  2022.0  534.0   525.0   265.0    260.0   0.000000   \n",
      "51852  1551.0    202.0  2023.0  581.0   490.0   260.0    230.0   5.000000   \n",
      "51853  1551.0    202.0  2024.0  599.0   495.0   265.0    230.0   7.953722   \n",
      "\n",
      "           p_geb       a_ste  ...  g_afs_kv  g_afs_sc  g_3km_sc  a_opp_ha  \\\n",
      "0       8.000000   90.000000  ...      0.40       0.5      12.2     101.0   \n",
      "1       7.000000  110.000000  ...      0.40       0.5      12.1     101.0   \n",
      "2       8.000000   85.000000  ...      0.40       0.5      10.4     102.0   \n",
      "3       7.000000  115.000000  ...      0.40       0.5      10.4     102.0   \n",
      "4       8.000000  100.000000  ...      0.40       0.5      10.4     106.0   \n",
      "...          ...         ...  ...       ...       ...       ...       ...   \n",
      "51849   0.000000   30.000000  ...      1.70       1.7       4.5    1141.0   \n",
      "51850   4.000000   30.000000  ...      1.70       1.7       4.6    1141.0   \n",
      "51851   2.000000   40.000000  ...      1.80       1.7       4.5    1141.0   \n",
      "51852  10.000000   30.000000  ...      1.70       1.7       4.6    1141.0   \n",
      "51853   7.359865    5.475195  ...      1.71       1.7       4.6    1141.0   \n",
      "\n",
      "       a_lan_ha  a_wat_ha  pst_mvp  pst_dekp  ste_mvs  ste_oad  \n",
      "0         101.0       0.0   2587.0       3.0      2.0   2363.0  \n",
      "1         101.0       0.0   2587.0       2.0      2.0   2464.0  \n",
      "2         102.0       0.0   2587.0       2.0      2.0   2469.0  \n",
      "3         102.0       0.0   2587.0       2.0      2.0   2438.0  \n",
      "4         106.0       0.0   2587.0       3.0      2.0   2446.0  \n",
      "...         ...       ...      ...       ...      ...      ...  \n",
      "51849    1053.0      87.0   8015.0       2.0      5.0    234.0  \n",
      "51850    1053.0      87.0   8015.0       2.0      5.0    234.0  \n",
      "51851    1053.0      87.0   8015.0       2.0      5.0    233.0  \n",
      "51852    1053.0      87.0   8015.0       2.0      5.0    246.0  \n",
      "51853    1053.0      87.0   8015.0       2.0      5.0    247.0  \n",
      "\n",
      "[51854 rows x 69 columns]\n"
     ]
    }
   ],
   "source": [
    "print(non_mis_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10f14f7b-ceaa-4d3b-8c7c-3a432e60af55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(non_mis_df.isnull().sum())\n",
    "\n",
    "end_df = non_mis_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59e77e66-f60f-42ed-b024-0c550f9f105e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51854 entries, 0 to 51853\n",
      "Data columns (total 71 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   regio     51854 non-null  object \n",
      " 1   gm_naam   51854 non-null  object \n",
      " 2   gwb_code  51854 non-null  object \n",
      " 3   ind_wbi   51854 non-null  int64  \n",
      " 4   year      51854 non-null  int64  \n",
      " 5   woz       51854 non-null  float64\n",
      " 6   a_inw     51854 non-null  float64\n",
      " 7   a_man     51854 non-null  float64\n",
      " 8   a_vrouw   51854 non-null  float64\n",
      " 9   a_geb     51854 non-null  float64\n",
      " 10  p_geb     51854 non-null  float64\n",
      " 11  a_ste     51854 non-null  float64\n",
      " 12  p_ste     51854 non-null  float64\n",
      " 13  a_hh      51854 non-null  float64\n",
      " 14  g_hhgro   51854 non-null  float64\n",
      " 15  bev_dich  51854 non-null  float64\n",
      " 16  a_woning  51854 non-null  float64\n",
      " 17  p_1gezw   51854 non-null  float64\n",
      " 18  p_mgezw   51854 non-null  float64\n",
      " 19  p_leegsw  51854 non-null  float64\n",
      " 20  p_koopw   51854 non-null  float64\n",
      " 21  p_huurw   51854 non-null  float64\n",
      " 22  p_wcorpw  51854 non-null  float64\n",
      " 23  p_ov_hw   51854 non-null  float64\n",
      " 24  g_ele     51854 non-null  float64\n",
      " 25  g_ele_vw  51854 non-null  float64\n",
      " 26  g_ele_hu  51854 non-null  float64\n",
      " 27  g_ele_ko  51854 non-null  float64\n",
      " 28  g_gas     51854 non-null  float64\n",
      " 29  g_gas_vw  51854 non-null  float64\n",
      " 30  g_gas_hu  51854 non-null  float64\n",
      " 31  g_gas_ko  51854 non-null  float64\n",
      " 32  a_inkont  51854 non-null  float64\n",
      " 33  g_ink_po  51854 non-null  float64\n",
      " 34  g_ink_pi  51854 non-null  float64\n",
      " 35  p_ink_li  51854 non-null  float64\n",
      " 36  p_ink_hi  51854 non-null  float64\n",
      " 37  p_hh_li   51854 non-null  float64\n",
      " 38  p_hh_hi   51854 non-null  float64\n",
      " 39  p_hh_lkk  51854 non-null  float64\n",
      " 40  p_hh_osm  51854 non-null  float64\n",
      " 41  a_soz_wb  51854 non-null  float64\n",
      " 42  a_soz_ao  51854 non-null  float64\n",
      " 43  a_soz_ww  51854 non-null  float64\n",
      " 44  a_soz_ow  51854 non-null  float64\n",
      " 45  a_bedv    51854 non-null  float64\n",
      " 46  a_bed_a   51854 non-null  float64\n",
      " 47  a_bed_bf  51854 non-null  float64\n",
      " 48  a_bed_gi  51854 non-null  float64\n",
      " 49  a_bed_hj  51854 non-null  float64\n",
      " 50  a_bed_kl  51854 non-null  float64\n",
      " 51  a_bed_mn  51854 non-null  float64\n",
      " 52  a_bed_ru  51854 non-null  float64\n",
      " 53  a_pau     51854 non-null  float64\n",
      " 54  a_bst_b   51854 non-null  float64\n",
      " 55  a_bst_nb  51854 non-null  float64\n",
      " 56  g_pau_hh  51854 non-null  float64\n",
      " 57  g_pau_km  51854 non-null  float64\n",
      " 58  a_m2w     51854 non-null  int64  \n",
      " 59  g_afs_hp  51854 non-null  float64\n",
      " 60  g_afs_gs  51854 non-null  float64\n",
      " 61  g_afs_kv  51854 non-null  float64\n",
      " 62  g_afs_sc  51854 non-null  float64\n",
      " 63  g_3km_sc  51854 non-null  float64\n",
      " 64  a_opp_ha  51854 non-null  float64\n",
      " 65  a_lan_ha  51854 non-null  float64\n",
      " 66  a_wat_ha  51854 non-null  float64\n",
      " 67  pst_mvp   51854 non-null  float64\n",
      " 68  pst_dekp  51854 non-null  int64  \n",
      " 69  ste_mvs   51854 non-null  int64  \n",
      " 70  ste_oad   51854 non-null  float64\n",
      "dtypes: float64(63), int64(5), object(3)\n",
      "memory usage: 28.1+ MB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3932/966619918.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[7885. 7955. 8055. ...  525.  490.  495.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  before_mice_df.loc[:, columns] = end_df.loc[:, columns]\n",
      "/tmp/ipykernel_3932/966619918.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[3900. 3935. 3980. ...  265.  260.  265.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  before_mice_df.loc[:, columns] = end_df.loc[:, columns]\n",
      "/tmp/ipykernel_3932/966619918.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[3980. 4020. 4075. ...  260.  230.  230.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  before_mice_df.loc[:, columns] = end_df.loc[:, columns]\n",
      "/tmp/ipykernel_3932/966619918.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[4110. 4130. 4180. ...  145.  140.  135.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  before_mice_df.loc[:, columns] = end_df.loc[:, columns]\n",
      "/tmp/ipykernel_3932/966619918.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[4035. 4091. 4102. ...  141.  140.  139.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  before_mice_df.loc[:, columns] = end_df.loc[:, columns]\n",
      "/tmp/ipykernel_3932/966619918.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[3060. 3080. 3085. ...  235.  230.  240.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  before_mice_df.loc[:, columns] = end_df.loc[:, columns]\n",
      "/tmp/ipykernel_3932/966619918.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[2620. 2635. 2615. ...  170.  160.  160.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  before_mice_df.loc[:, columns] = end_df.loc[:, columns]\n",
      "/tmp/ipykernel_3932/966619918.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[440. 450. 470. ...  65.  70.  75.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  before_mice_df.loc[:, columns] = end_df.loc[:, columns]\n",
      "/tmp/ipykernel_3932/966619918.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 101.  101.  102. ... 1141. 1141. 1141.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  before_mice_df.loc[:, columns] = end_df.loc[:, columns]\n",
      "/tmp/ipykernel_3932/966619918.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 101.  101.  102. ... 1053. 1053. 1053.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  before_mice_df.loc[:, columns] = end_df.loc[:, columns]\n",
      "/tmp/ipykernel_3932/966619918.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.  0.  0. ... 87. 87. 87.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  before_mice_df.loc[:, columns] = end_df.loc[:, columns]\n",
      "/tmp/ipykernel_3932/966619918.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[2587. 2587. 2587. ... 8015. 8015. 8015.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  before_mice_df.loc[:, columns] = end_df.loc[:, columns]\n",
      "/tmp/ipykernel_3932/966619918.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[2363. 2464. 2469. ...  233.  246.  247.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  before_mice_df.loc[:, columns] = end_df.loc[:, columns]\n"
     ]
    }
   ],
   "source": [
    "columns = end_df.columns.drop(['gm_naam', 'regio'])\n",
    "\n",
    "before_mice_df.loc[:, columns] = end_df.loc[:, columns]\n",
    "\n",
    "print(before_mice_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0df4840f-4138-4f50-9bf9-e23de4c2f834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regio</th>\n",
       "      <th>gm_naam</th>\n",
       "      <th>gwb_code</th>\n",
       "      <th>ind_wbi</th>\n",
       "      <th>year</th>\n",
       "      <th>woz</th>\n",
       "      <th>a_inw</th>\n",
       "      <th>a_man</th>\n",
       "      <th>a_vrouw</th>\n",
       "      <th>a_geb</th>\n",
       "      <th>...</th>\n",
       "      <th>g_afs_kv</th>\n",
       "      <th>g_afs_sc</th>\n",
       "      <th>g_3km_sc</th>\n",
       "      <th>a_opp_ha</th>\n",
       "      <th>a_lan_ha</th>\n",
       "      <th>a_wat_ha</th>\n",
       "      <th>pst_mvp</th>\n",
       "      <th>pst_dekp</th>\n",
       "      <th>ste_mvs</th>\n",
       "      <th>ste_oad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Belgisch Park</td>\n",
       "      <td>'s-Gravenhage</td>\n",
       "      <td>BU05180271</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>300.0</td>\n",
       "      <td>7885.0</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>3980.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>12.2</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2587.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2363.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Belgisch Park</td>\n",
       "      <td>'s-Gravenhage</td>\n",
       "      <td>BU05180271</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>294.0</td>\n",
       "      <td>7955.0</td>\n",
       "      <td>3935.0</td>\n",
       "      <td>4020.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>12.1</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2587.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2464.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Belgisch Park</td>\n",
       "      <td>'s-Gravenhage</td>\n",
       "      <td>BU05180271</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>298.0</td>\n",
       "      <td>8055.0</td>\n",
       "      <td>3980.0</td>\n",
       "      <td>4075.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.4</td>\n",
       "      <td>102.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2587.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2469.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Belgisch Park</td>\n",
       "      <td>'s-Gravenhage</td>\n",
       "      <td>BU05180271</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>312.0</td>\n",
       "      <td>8145.0</td>\n",
       "      <td>4025.0</td>\n",
       "      <td>4120.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.4</td>\n",
       "      <td>102.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2587.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2438.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Belgisch Park</td>\n",
       "      <td>'s-Gravenhage</td>\n",
       "      <td>BU05180271</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>339.0</td>\n",
       "      <td>8210.0</td>\n",
       "      <td>4030.0</td>\n",
       "      <td>4175.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.4</td>\n",
       "      <td>106.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2587.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2446.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           regio        gm_naam    gwb_code  ind_wbi  year    woz   a_inw  \\\n",
       "0  Belgisch Park  's-Gravenhage  BU05180271        1  2014  300.0  7885.0   \n",
       "1  Belgisch Park  's-Gravenhage  BU05180271        1  2015  294.0  7955.0   \n",
       "2  Belgisch Park  's-Gravenhage  BU05180271        1  2016  298.0  8055.0   \n",
       "3  Belgisch Park  's-Gravenhage  BU05180271        1  2017  312.0  8145.0   \n",
       "4  Belgisch Park  's-Gravenhage  BU05180271        1  2018  339.0  8210.0   \n",
       "\n",
       "    a_man  a_vrouw  a_geb  ...  g_afs_kv  g_afs_sc  g_3km_sc  a_opp_ha  \\\n",
       "0  3900.0   3980.0   65.0  ...       0.4       0.5      12.2     101.0   \n",
       "1  3935.0   4020.0   60.0  ...       0.4       0.5      12.1     101.0   \n",
       "2  3980.0   4075.0   65.0  ...       0.4       0.5      10.4     102.0   \n",
       "3  4025.0   4120.0   60.0  ...       0.4       0.5      10.4     102.0   \n",
       "4  4030.0   4175.0   65.0  ...       0.4       0.5      10.4     106.0   \n",
       "\n",
       "   a_lan_ha  a_wat_ha  pst_mvp  pst_dekp  ste_mvs  ste_oad  \n",
       "0     101.0       0.0   2587.0         3        2   2363.0  \n",
       "1     101.0       0.0   2587.0         2        2   2464.0  \n",
       "2     102.0       0.0   2587.0         2        2   2469.0  \n",
       "3     102.0       0.0   2587.0         2        2   2438.0  \n",
       "4     106.0       0.0   2587.0         3        2   2446.0  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_mice_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf40dcb5-f664-4f3a-88f0-e3cd8dde4b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_mice_df.to_csv('/home/wouter/Documents/Scriptie/predicting/ENDCBSFILE.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
